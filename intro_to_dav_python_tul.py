# -*- coding: utf-8 -*-
"""intro_to_dav_python_TUL

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PUjsWMNBDFauftaiD6lRGWfiUzZD5D3S

# <center>**Introduction to Data Analysis and Visualization in Python**
##<center>Tulane University Libraries<br>
###<center>K. Maye | Scholarly Engagement Librarian for Social Sciences and Data 

###<center>Be sure to follow along with the text and green commnets.

<center> <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.

### **Installing and Importing Pandas**

### **For this analysis and visualization workflow, we will be using the pandas library. To learn more about pandas, visit the following link: https://pandas.pydata.org/**

### To use this library, we must import it into our coding environment. We will also assign a nickname to the library to make it easily accesibly. We will import more libraries throughout this tutorial.
"""

import pandas as pd

"""###**Importing .csv Files**

### Follow the instructions on the Library Guide 
### [Importing and Previwing Data](https://libguides.tulane.edu/c.php?g=1258147&p=9481618) to upload the data file into Google Colab.
"""

#Use the read_csv() function from pandas to import the dataset into the environment.
# We will store the dataset as the variable data.
# The pd. before the function is used to specify the location of the function.
#In this instance the function lives in the pandas library.

data = pd.read_csv("./imdb_workshop.csv")

#The .head method is used to preview the first five records in a dataset. 
#Add a number inside the parentheses to specify the number of records you wish to display.

data.head()

"""###***Generating Descriptive Statistics for Textual and Numeric Data*** """

# To learn more about your data columns, use .info()

data.info()

#.describe() is another way to generate information about your dataset.
# This method offers descriptive statistics about your numeric data.

data.describe()

# To include descriptive information about both your textual and numeric data,
# use include = "all" as an argument for the method.

data.describe(include ="all")

"""##**Cleaning Your Data**

### After collecting raw data, you may find that the information you collected should be "cleaned" to make your analysis more meaningful.

##***Checking Number of Missing Values***

### To address the remaining missing numeric values, we will replace the missing values with the mean of the column. Before conducting this process with your data, be sure that column mean is the most appropriate method for your data set. You may also replace missing values with column medians depending on the spread of your data.
"""

# Stack the .isna() and .sum() methods to calculate the number of missing values
# per column.
data.isna().sum()

"""###**Creating Mean Variables**"""

#We will focus on replacing the missing values in Metascore and Gross_in_$_M.
#To do so, we will create a variable that stores the mean of each column.

avg_metascore = data['Metascore'].mean(axis=0)
avg_gross = data['Gross_in_$_M'].mean(axis=0)

print (avg_metascore)
print (avg_gross)

"""###**Importing Numpy**"""

#Numpy is a library that gives you advanced mathematical functionality.

import numpy as np

"""###**Replacing Values**"""

#To replace the missing values, we will use the .replace method on each of the 
# columns. In this example, we us np.nan to represent the missing values we
# want to replace. Setting inplace = True ensures that your changes update to
# the original dataset.

data['Metascore'].replace( np.nan ,avg_metascore, inplace = True )

data['Gross_in_$_M'].replace( np.nan ,avg_gross, inplace = True)

"""###**Checking Updated Data**"""

#Use .isna().sum() to ensure that your missing values have been replaced.
data.isna().sum()

"""###**Changing Column Names**"""

#To make the dataset easier to use, we will change each column name to lowercase.
# We will also shorten some column names. 
#To do so, we will use the .rename method. This method allows you to create a
# dictionary that replaces the original column name with your preferred name.
# Once again, we will use inplace=True to save the changes to the original data.

data.rename(columns={'Rank':'rank',
                     'Movie_name':'film', 
                     'Year':'year',
                     'Certificate':'rating',
                     'Runtime_in_min':'runtime',
                     'Genre':'genre',
                     'Metascore':'metascore',
                     'Gross_in_$_M':'gross_in_m',
                     'Rating_from_10':'score'}, inplace = True)

#Use .info() to check your work.

data.info()

"""###**Changing Column Data Type**"""

#Since the rank column represents a position, we will change it to 
# text data instead of numeric data.

data['rank'] = data['rank'].astype(str)

#Use .info() to check your work.

data.info()

"""### **Subsetting Dataset Based on a Condition**"""

#For the purpose of this analysis, we will only need the common film ratings,
# so we will need to subset the data to only include the films with these ratings.
# To help with this process, we will make a list of ratings that we 
# want to include in our analysis.

list1 = ['R', 'PG-13', 'PG', 'G']

#We will create a new dataset known as rated_data to store the data.
# To subset the data, we will access the original rating column and extract
# the films that meet our criteria using the .isin method.

rated_data = data[(data['rating'].isin(list1))]

#Check your new variable. Notice that this new dataset has less records.

rated_data.info()

"""### **Splitting Columns Based on a Delimeter**"""

# To make our data more atomic, we will split the genre cell since
# it often times contains more than 1 genre.

rated_data["genre"].head()

#We will create 3 new columns to hold the data we will split. When using this
# workflow, check to see the maximum number of items in each row. 

# To the right of the equation sign, we are using the str.split method to split our string text.
# Notice that this method takes two arguments. 

#The first is the delimeter. This is the character you want to separate your text on.
#The second is the expand argument which tells the the system to create these new cells 
# next to the original cells. 

rated_data[['genre1', 'genre2', 'genre3']] = rated_data.genre.str.split(",", expand=True)

# Use the .head() method to see the new columns
rated_data.head()

#Remove the original genre column from the dataset

del rated_data['genre']

#Using the .info() method shows that your columns are updated.

rated_data.info()

"""### **Determine Correlation of Numeric Data**"""

#You can easily find the correlation between your numeric values using
# the .corr() method on the dataset
# defaults to pearson coefficient

rated_data.corr()

"""###**Produce Descriptive Statistics for Textual and Numeric Data**"""

#Now that the data is clean, let's take a new look at the dataset's
# numeric descriptive statistics.

rated_data.describe()

#Again, you'll use the include = "all" method to see the descriptive information
# for textual data as well.

rated_data.describe(include='all')

"""### **Using the Sweetviz Library to Review Data**

### Sweetviz is a library you can use to help speed up your data analysis!
"""

# Use pip to install the sweetviz library

! pip install sweetviz

#import the library into your coding environment

import sweetviz as sv

# We will use the analyze function from the sweetviz library to
# create a report of our data

descriptive_report = sv.analyze(rated_data)

#Now that you've created and stored the report, you can render the
# report as an html file. You're html file will save to the files folder 
# on the left side of the screen.

descriptive_report.show_html('movie_data.html')

"""### **Univariate Visualizations**

### Univariate visualizations allow you to explore one variable of your data.

### We will use the plotly.express library to create our visualizations. For more on how to use plotly.express, visit the following link: https://plotly.com/python/plotly-express/
"""

#import the library and give it a nickname

import plotly.express as px

"""### **Bar and Histogram Plots**"""

# Histograms are used to show the spread of values across
# a certain range. In this example, we are looking at the number of 
# movies released across our date range.

fig = px.histogram(rated_data, x ='year', title="Movie Year Distribution")


# The .update_layout() method allows you to make stylistic changes to your visualizations.

fig.update_layout(
    yaxis_title_text='Movie Year Distribution', 
    font_size=14,
    title_font_color = "green", 
    font_color = "green", xaxis_dtick = 10)

# Use the .show() to display your visualization. You can also save your
# visualizations by pressing the camera icon on the top right of the visualization.

fig.show()

# Bar charts are used to show the number of instances in categorical data.
# In this example, we are visualizing the number of films assigned each rating.

fig = px.bar(rated_data, x = 'rating')

#As with the previous example, you can use .update_layout() to add details
# to your visualization.

fig.update_layout(
    yaxis_title_text='Rating Distribution', 
    font_size=14,
    title_font_color = "green", 
    font_color = "green")

fig.show()

"""### **Box Plot**"""

# Box plots help you visualize the "spread" of a specific data point.

fig = px.box(rated_data, x ='metascore')

fig.update_layout(
    yaxis_title_text='Metascore Distribution', 
    font_size=14,
    title_font_color = "green", 
    font_color = "green")

# update_traces() is another method used to update the visual aspects of your 
# plot.

fig.update_traces(line_color= "green", marker_color = "blue", marker_size = 4,
                 hoverlabel_bgcolor="white")

fig.show()

"""### **Pie Chart**"""

# Pie charts are used to help visualize categorical data.

fig = px.pie (rated_data, names='rating')

fig.update_traces(textfont_size=20, textposition = "outside", hole=.5)

fig.show()

"""### **Line Chart - Time Series Analysis**"""

#To perform this time series analysis, we need to restructure
# our data.

# Use the .groupby() method to create a new data set that groups the 
# data by year. The .mean() method creates this data based on the mean
# of all numeric values.

result = rated_data.groupby('year').mean()
print (result)

# We can now use the a line chart to visualize our reorganized data. For example,
# we will view the gross_in_m over time using the line chart in the plotly express
# library.

fig = px.line(result['gross_in_m'])

# You can change the column name to view any of the other variables over time.

fig.show()

"""### **Multivariate Analysis**

### Mulitvariate visualizations allows you to see multiple variables plotted against each other.
"""

#Scatter plots are used to show the potential correlation between two variables.
#In this example, we use the scatter plot to see if there is a relationship 
# between the score and metascore variables.

fig = px.scatter( rated_data, x = 'score', y = 'metascore', color_discrete_sequence = ['green'], trendline ='ols' )

#The trendline argument can be used to summarize the relationship.

fig.show()

#We can also create box plots that use visualize more than one variable at a time.
# This examples shows the use of the color argument. Assigning a column
# to the color argument separates your data based on the values in that column.

fig = px.box (rated_data, y='score', color = 'rating')

fig.show()

"""### **Save Data File**"""

# Using the .to_csv method saves your data as a csv file. The file will be saved
# to the current working directory. In this case, the file will be saved to the
# files folder to the left.

rated_data.to_csv('./clean_movie_data')

"""# <center>Thanks for using this file as you learn Python! Feel free to contact Kay P Maye (kmaye@tulane.edu) with any questions, concerns, or suggestions.</center>

"""